<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Genetic studies | Xianjing Liu</title> <meta name="author" content="Xianjing Liu"> <meta name="description" content="A fully data-driven approach for genome-wide-association stuides (GWAS) with image-based phenotypes"> <meta name="keywords" content="machine/deep learning, interpretability, confounders, imaging genetics, epidemiological studies"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tsingmessage.github.io/projects/5_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Xianjing Liu</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Genetic studies</h1> <p class="post-description">A fully data-driven approach for genome-wide-association stuides (GWAS) with image-based phenotypes</p> </header> <article> <p>Genome-wide association study (GWAS) has been pivotal in identifying genetic loci associated with specific phenotypes of scientific interest. Although highly effective in various applications, the conventional GWAS framework is inherently designed for single phenotypic traits, posing significant challenges when applied to complex medical image-based phenotypes. Defining phenotypes that capture the full variance of an image is difficult, requiring careful consideration of multiple testing corrections due to the large number of correlated phenotypes, and making the interpretation of results intractable.</p> <p>Throughout the literature, several strategies have been proposed to tackle these challenges. One approach involves the direct utilization of each pixel or voxel within an image as a phenotype for GWAS, while another entails deriving prior-defined measurements from images as phenotypes. For example, the derivation of facial landmarks from facial images, and the region-of-interest volume from brain MRI scans. Although these strategies yield commendable outcomes with a large sample size, the real potential lies in seeking solutions that delve into image phenotypes in a more data driven manner, which goes beyond a priory defined knowledge.</p> <p>Recent breakthroughs in artificial intelligence (AI) models have demonstrated great data-driven capabilities in preserving essential information while reducing high-dimensional image data into low-dimensional representations. This pivotal advancement has inspired pioneering researchers to leverage AI-derived low-dimensional representations, namely endophenotypes, as phenotypes for GWAS. Notably, this approach has proven fruitful in various contexts, such as unsupervised autoencoder-based endophenotypes for 3D brain images and 3D cardiac mesh images, self-supervised contrastive learning for molecular imaging, and transfer learning for retinal fundus images. However, so far only single-trait GWAS has been applied to endophenotypes, the potential of combing multiple endophenotypes has not yet been explored. Given that a SNP might have pleiotropic effects on multiple endophenotypes, we propose to combine the effects of multiple endophenotypes by using the combine-GWAS <a href="https://www.nature.com/articles/s41467-022-35328-9" rel="external nofollow noopener" target="_blank">(C-GWAS)</a> approach. This approach is known for its capacity to augment the relationship between phenotypes and genetic variants by fusing multiple phenotypes.</p> <p>Another important concern in the AI-based phenotyping approaches is the need of sharing individual data when conducting collaborations with multiple cohorts. Such collaboration is especially essential for conducting any well powered GWAS analysis. The underlying reason for this issue lies in the nature of the AI based data-driven approaches, where (endo)phenotypes are determined by the distribution of the local training data. If not sharing individual data in the training of model parameters, the definition of phenotypes differs from one cohort to another, and thus it will be difficult to analyse multiple cohorts. To address this, we propose to address scenarios involving multiple cohorts by harnessing federated learning techniques, eliminating the requirement for sharing image data, but obtaining integrated model parameters</p> <p>In summary, we propose a pipeline (Figure 1) to unlock the potential of image-based complex traits within GWAS through a synergistic fusion of data-driven AI phenotyping techniques and advanced statistical methodologies (i.e., the C-GWAS). To empirically exemplify its practical suitability, we applied the proposed AI pipeline to facial shape data from the Generation R Study (N=3,314) and the Rotterdam Study (N=3,995). We exploited the federated learning techniques to derive consistently defined 200 facial endophenotypes from two cohorts. Further GWAS, meta-analysis and C-GWAS not only uncovers novel genomic loci within a mediocre study population but also visually interprets associated phenotypes through facial heatmaps. Furthermore, by integrating techniques from federated learning, we also demonstrate the success in our pipeline to collaborate more data from multiple cohorts to reach a better power with a large sample size.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/0051-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/0051-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/0051-1400.webp"></source> <img src="/assets/img/0051.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The framework of our pipeline, including AI-based phenotyping, single-trait GWAS, and C-GWAS. </div> <p>Figure below shows the Manhattan plot of our c-GWAS results, together with facial phenotypes associated with each leading SNP. In total of 43 genomic loci were identified, of which 12 have not been previously reported in existing studies.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/0052-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/0052-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/0052-1400.webp"></source> <img src="/assets/img/0052.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Manhattan plot of our c-GWAS results. Red areas refer to inward changes while blue areas refer to outward changes of the face with respect to the geometric center of the head. </div> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Xianjing Liu. Last updated: March 06, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>